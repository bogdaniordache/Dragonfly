[
{
	"uri": "https://d7y.io/api_reference/api_supernode/",
	"title": "APIs Provided by Supernode",
	"tags": [],
	"description": "",
	"content": "This topic explains how to use the APIs provided by Supernode. This section describes APIs that is provided by the supernode, aka cluster manager.\nRegistration POST /peer/registry  Parameters\nParameters are encodeds as application/x-www-form-urlencoded.\n cid: string, the client id. ip: ipv4 string, the client ip address. hostName: string, the host name of client node. superNodeIp: ipv4 string, the ip address of super node. port: integer, the port which client opens. callSystem: string, the caller identifier. version: string, client version. dfdaemon: boolean, tells whether it is a call from dfdaemon. path: string, the path which client can serve. rawUrl: string, the resource url provided by command line parameter. taskUrl: string, the resource url. md5: string, the md5 checksum for the resource, optional. identifier: string, identifer for the resource. headers: map, extra http headers sent to the raw url.  Under the scene, the cluster manager creates a new instance of Task, which is built from the information provided by parameters. Specifically, it generates a taskId based on rawUrl, md5 and identifier.\nThen the task would be saved in the memory state. At the same time, it will fetch extra information like the content-length which would generally be set. Also, the pieceSize is computed with the strategy below:\n if the total size is less than 200MB, the piece size would be 4MB by default. otherwise, the minimum of (${totalSize} / 100MB) + 2MB and 15MB.  The next step is, the peer information along with the task will be recorded:\n The peerwill be saved. The taskwill be saved.  The last step is about triggering a progress.\nResponse\nAn example response:\n{ \u0026quot;code\u0026quot;: 200, \u0026quot;data\u0026quot;: { \u0026quot;fileLength\u0026quot;: 687481, \u0026quot;pieceSize\u0026quot;: 4194304, \u0026quot;taskId\u0026quot;: \u0026quot;ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot; } }  Other cases could happen:\n the task id might duplicate with an existing one. 606 the url might be invalid. 607 the access requires authentication. 608 or 609  Get Task GET /peer/task  Parameters\nParameters are encoded as query string.\n superNode: ipv4 string, the ip address of super node. dstCid: string, destination client id. range: string, byte range. status: integer. result: integer. taskId: string, the task id. srcCid: string, the source client id.  The super node will analyze the status and result firstly:\n Running if status == 701. Success if status == 702 and result == 501. Fail if status == 702 and result == 500. Wait if status == 700.  In waiting status, the super node would:\n Save the status to be running.  In running status, the super node would will extract the piece status:\n Success if result == 501. Fail if result == 500. SemiSuc if result == 503.  (side note): result == 502 means invalid code.\nAnd update the progress for this specific task. Then it checks the status itself and also the peer status, after that, the super node will tell the client another task which has enough detail for the next piece, or fails if no one is available.\nResponse\nAn example resonse:\n{ \u0026quot;code\u0026quot;: 602, \u0026quot;msg\u0026quot;: \u0026quot;client sucCount:0,cdn status:Running,cdn sucCount: 0\u0026quot; }  This means the client has to wait, since no peer can serve this piece now. And if there is a peer which can serve this request, there will be a response like this:\n{ \u0026quot;code\u0026quot;: 601, \u0026quot;data\u0026quot;: [ { \u0026quot;cid\u0026quot;: \u0026quot;cdnnode:10.148.177.242~ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot;, \u0026quot;downLink\u0026quot;: \u0026quot;20480\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/qtdown/ba2/ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot;, \u0026quot;peerIp\u0026quot;: \u0026quot;10.148.177.242\u0026quot;, \u0026quot;peerPort\u0026quot;: 8001, \u0026quot;pieceMd5\u0026quot;: \u0026quot;d78ef0af9e95e880fa583b41cf5ad791:687486\u0026quot;, \u0026quot;pieceNum\u0026quot;: 0, \u0026quot;pieceSize\u0026quot;: 4194304, \u0026quot;range\u0026quot;: \u0026quot;0-4194303\u0026quot; } ] }  Peer Progress GET /peer/piece/suc  Parameters\nParameters are encoded as query string.\n dstCid: string, the destination client id. pieceRange: byte range. taskId: string, the task id. cid: string, the client id.  Response\nAn example response:\n{ \u0026quot;code\u0026quot;: 200, \u0026quot;msg\u0026quot;: \u0026quot;success\u0026quot; } "
},
{
	"uri": "https://d7y.io/onboarding/",
	"title": "Before Starting",
	"tags": [],
	"description": "",
	"content": " Before getting started, let\u0026rsquo;s take a quick look at how to use this documentation portal of Dragonfly.\nNavigating With a rich set of navigation features, you can always locate your target resource at ease.\nNavigating to the Homepage To go to the homepage of the Dragonfly documentation portal, do one of the following:\n In the breadcrumb of any page, click Dragonfly. In the address bar of the browser, type https://alibaba.github.io/Dragonfly/ and press Enter.  Navigating to a Topic To navigate to a topic, do one of the following:\n In the left-side navigation pane, click a chapter title to expand this chapter, and then click a child topic. In the left-side navigation pane, click a chapter title, and then on the right-side reading pane, click the child topic link.  Navigating to a Specific Section of a Topic Some topics can be lengthy. To jump to a specific section, do the following:\n Hover-over the mini TOC icon in the breadcrumb.\n In the mini TOC overlay, click a section heading.\n  Navigating to Other Related Resources To navigate to other related resources, such as the Dragonfly roadmap, github repo, contributing guide, and so on, click the link under More in the left-side navigation pane.\nSearching Given that the Dragonfly documentation portal is a static website, you can find target information in a blink of an eye.\nTo perform a search, type your key words in the search box on the top of the left-side navigation pane, and matching results will appear in the overlay.\nIn the search results, click any link to jump to the topic, and your key words will be highlighted in yellow.\nImproving the Documentation If you see a typo, or just feel like adding your insights, don\u0026rsquo;t hesitate to click the Edit this page link in the breadcrumb. Then you\u0026rsquo;ll be prompted to sign in your Github account and fork the repository.\n"
},
{
	"uri": "https://d7y.io/user_guide/install_server/",
	"title": "Installing Server",
	"tags": [],
	"description": "",
	"content": "This topic explains how to install the Dragonfly server. For a data center or a cluster, we recommend that you use at least two machines with eight cores, 16GB RAM and Gigabit Ethernet connections for deploying supernodes.\n Context There are two layers in Dragonfly’s architecture: server (supernodes) and client (hosts). Install the supernodes in one of the following ways:\n Deploying with Docker: Recommended for quick local deployment and test. Deploying with physical machines: Recommended for production usage.  Prerequisites When deploying with Docker, the following conditions must be met.\n   Required Software Version Limit     Git 1.9.1+   Docker 1.12.0+    When deploying with physical machines, the following conditions must be met.\n   Required Software Version Limit     Git 1.9.1+   JDK 1.7+   Maven 3.0.3+   Nginx 0.8+    Procedure - When Deploying with Docker  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the project directory.\ncd Dragonfly  Build the Docker image.\n./build/build.sh supernode  Obtain the latest Docker image ID of the supernode.\ndocker image ls|grep 'supernode' |awk '{print $3}' | head -n1  Start the supernode.\n# Replace ${supernodeDockerImageId} with the ID obtained at the previous step docker run -d -p 8001:8001 -p 8002:8002 ${supernodeDockerImageId}   Procedure - When Deploying with Physical Machines  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the project directory.\ncd Dragonfly/src/supernode  Compile the source code.\nmvn clean -U install -DskipTests=true  Start the supernode.\n# If the 'supernode.baseHome’ is not specified, then the default value '/home/admin/supernode’ will be used. java -Dsupernode.baseHome=/home/admin/supernode -jar target/supernode.jar  Add the following configuration items to the Nginx configuration file.\nThe path of the Nginx configuration file is something like src/supernode/src/main/docker/sources/nginx.conf.\n server { listen 8001; location / { # Must be ${supernode.baseHome}/repo root /home/admin/supernode/repo; } } server { listen 8002; location /peer { proxy_pass http://127.0.0.1:8080; } }  Start Nginx.\nsudo nginx   After this Task  After the supernode is installed, run the following commands to verify if Nginx and Tomcat are started, and if Port 8001 and 8002 are available.\nps aux|grep nginx ps aux|grep tomcat telnet 127.0.0.1 8001 telent 127.0.0.1 8002  Install the Dragonfly client and test if the downloading works.\ndfget --url \u0026quot;http://${resourceUrl}\u0026quot; --output ./resource.png --node \u0026quot;127.0.0.1\u0026quot;  "
},
{
	"uri": "https://d7y.io/overview/what_is_dragonfly/",
	"title": "What Is Dragonfly?",
	"tags": [],
	"description": "",
	"content": "Dragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution. At Alibaba, every month Dragonfly is invoked two billion times and distributes 3.4PB of data. Dragonfly has become one of the most important pieces of infrastructure at Alibaba.\nWhile container technologies makes DevOps life easier most of the time, it surely brings some challenges: for example the efficiency of image distribution, especially when you have to replicate image distribution on several hosts.\nDragonfly works extremely well with both Docker and PouchContainer in this scenario. It\u0026rsquo;s also compatible with containers of other formats. It delivers up to 57 times the throughput of native docker and saves up to 99.5% of the out bandwidth of registry.\nDragonfly makes it simple and cost-effective to set up, operate, and scale any kind of file, image, or data distribution.\nWhy Dragonfly This project is an open-source version of the Dragonfly used at Alibaba. It has the following features:\nMore Alibaba-internal features will be made available to open-source users soon. Stay tuned!\n  P2P-based file distribution: By using the P2P technology for file transmission, it makes the most out of the bandwidth resources of each peer to improve downloading efficiency, and saves a lot of cross-IDC bandwidth, especially the costly cross-board bandwidth. Non-invasive support to all kinds of container technologies: Dragonfly can seamlessly support various containers for distributing images. Host level speed limit: In addition to rate limit for the current download task like many other downloading tools (for example wget and curl), Dragonfly also provides rate limit for the entire host. Passive CDN: The CDN mechanism can avoid repetitive remote downloads. Strong consistency: Dragonfly can make sure that all downloaded files are consistent even if users do not provide any check code (MD5). Disk protection and highly efficient IO: Prechecking disk space, delaying synchronization, writing file blocks in the best order, isolating net-read/disk-write, and so on. High performance: Cluster Manager is completely closed-loop, which means that it doesn\u0026rsquo;t rely on any database or distributed cache, processing requests with extremely high performance. Auto-isolation of Exception: Dragonfly will automatically isolate exception nodes (peer or Cluster Manager) to improve download stability. No pressure on file source: Generally, only a few Cluster Managers will download files from the source. Support standard HTTP header: Support submitting authentication information through HTTP header. Effective concurrency control of Registry Auth: Reduce the pressure on the Registry Auth Service. Simple and easy to use: Very few configurations are needed.  How Does It Stack Up Against Traditional Solution? We carried out an experiment to compare the performance of Dragonfly and wget.\n   Test Environment      Dragonfly Server 2 * (24-Core 64GB-RAM 2000Mb/s)   File Source Server 2 * (24-Core 64GB-RAM 2000Mb/s)   Client 4-Core 8GB-RAM 200Mb/s   Target File Size 200MB   Experiment Date April 20, 2016    The expeirment result is as shown in the following figure.\nAs you can see in the chart, for Dragonfly, no matter how many clients are downloading, the average downloading time is always about 12 seconds. But for wget, the downloading time keeps increasing with the number of clients. When the number of wget clients reaches 1,200, the file source crashed and therefore cannot serve any client.\nHow Does It Work? Dragonfly works slightly differently when downloading general files and downloading container images.\nDownloading General Files The Cluster Manager is also called a supernode, which is responsible for CDN and scheduling every peer to transfer blocks between each other. dfget is the P2P client, which is also called \u0026ldquo;peer\u0026rdquo;. It\u0026rsquo;s mainly used to download and share blocks.\nDownloading Container Images Registry is similar to the file server above. dfget proxy is also called dfdaemon, which intercepts HTTP requests from docker pull or docker push, and then decides which requests to process with dfget.\nDownloading Blocks Every file is divided into multiple blocks, which are transmitted between peers. Each peer is a P2P client. Cluster Manager will check if the corresponding file exists in the local disk. If not, it will be downloaded into Cluster Manager from file server.\n"
},
{
	"uri": "https://d7y.io/cli_reference/dfdaemon/",
	"title": "dfdaemon",
	"tags": [],
	"description": "",
	"content": " dfdaemon This topic explains how to use the dfdaemon command.\nNAME dfdaemon - a proxy between pouchd/dockerd and registry used for pulling images.\nSYNOPSIS dfdaemon [options]\u0026hellip;\nOPTIONS -callsystem string caller name (default \u0026quot;com_ops_dragonfly\u0026quot;) -certpem string cert.pem file path -dfpath string dfget path (default is your installed path) -h\thelp -hostIp string dfdaemon host ip, default: 127.0.0.1 (default \u0026quot;127.0.0.1\u0026quot;) -keypem string key.pem file path -localrepo string temp output dir of dfdaemon (default is \u0026quot;${HOME}/.small-dragonfly/dfdaemon/data\u0026quot;) -maxprocs int the maximum number of CPUs that the dfdaemon can use (default 4) -notbs not try back source to download if throw exception (default true) -port uint dfdaemon will listen the port (default 65001) -ratelimit string net speed limit,format:xxxM/K -registry string registry addr(https://abc.xx.x or http://abc.xx.x) and must exist if dfdaemon is used to mirror mode -rule string download the url by P2P if url matches the specified pattern,format:reg1,reg2,reg3 -urlfilter string filter specified url fields (default \u0026quot;Signature\u0026amp;Expires\u0026amp;OSSAccessKeyId\u0026quot;) -v\tversion -verbose verbose  FILES Local Repository Directory The default local repository is: ${HOME}/.small-dragonfly/dfdaemon/data/, you can change it by setting the option: -localrep.\n"
},
{
	"uri": "https://d7y.io/user_guide/install_client/",
	"title": "Installing Client",
	"tags": [],
	"description": "",
	"content": "You have two options when installing the Dragonfly client: installing from the latest package, or installing from the source code. Installing from the Latest Package You can install from the latest packages we provided.\n Download a package of the client.\ncd $HOME # Replace ${package} with a package appropriate for your operating system and location wget ${package}  Available packages:\n If you\u0026rsquo;re in China:\n Linux 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_darwin_amd64.tar.gz\n  If you\u0026rsquo;re not in China:\n Linux 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_darwin_amd64.tar.gz\n   Unzip the package.\n# Replace `xxx` with the installation directory. tar -zxf df-client_0.2.0_linux_amd64.tar.gz -C xxx  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Replace `xxx` with the installation directory. # Execute or add this line to ~/.bashrc export PATH=$PATH:xxx/df-client/   Installing from the Source Code You can also install from the source code.\nYou must have installed Go 1.7+, and added the Go command to the PATH environment variable.\n Installing in $HOME/.dragonfly  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the target directory.\ncd Dragonfly  Install dfdaemon and dfget in $HOME/.dragonfly/df-client.\n./build/build.sh client  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=$HOME/.dragonfly/df-client:$PATH   Installing in Another Directory  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the target directory.\ncd Dragonfly/build/client  Install the client.\n./configure --prefix=${your_installation_directory} make \u0026amp;\u0026amp; make install  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=${your_install_directory}/df-client:$PATH   After this Task Test if the downloading works.\n```sh dfget --url \u0026quot;http://${resourceUrl}\u0026quot; --output ./resource.png --node \u0026quot;127.0.0.1\u0026quot; ``` "
},
{
	"uri": "https://d7y.io/api_reference/api_preheat/",
	"title": "Preheat API",
	"tags": [],
	"description": "",
	"content": "This topic explains how to use the Preheat API. GET /api/check  check whether the connection to Dragonfly is available\n  Parameters Response: Content-type: application/json HTTP CodeResponse Body   200   { \u0026ldquo;code\u0026rdquo;: 200 }      POST /api/preheat  request to Dragonfly to start a preheat task\n  Parameters: Content-type: application/json Parameter TypeData Type  body  { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;image|file\u0026rdquo;, \u0026ldquo;url\u0026rdquo;: \u0026ldquo;\u0026lt;string\u0026gt;\u0026rdquo;, \u0026ldquo;header\u0026rdquo;: { \u0026ldquo;\u0026lt;name\u0026gt;\u0026ldquo;: \u0026ldquo;\u0026lt;value\u0026gt;\u0026ldquo; } } Dragonfly sends a request taking the \u0026lsquo;header\u0026rsquo; to the \u0026lsquo;url\u0026rsquo;.   If there is any authentication step of the remote server, the header should contain authenticated information.\nIf the type is image, then the url should be image url: \u0026lt;registry_host\u0026gt;/\u0026lt;image_name\u0026gt;:\u0026lt;image_tag\u0026gt;. Dragonfly will preheat the image according to registry API spec, the steps are: * construct manifest_url:\n ``` https://\u0026lt;harbor_host\u0026gt;/v2/\u0026lt;image_name\u0026gt;/manifests/\u0026lt;image_tag\u0026gt; ```   pull the manifest of the image from manifest_url get the fsLayers from manifest and construct layer_url of each layer:\n https://\u0026lt;harbor_host\u0026gt;/v2/\u0026lt;name\u0026gt;/blobs/\u0026lt;digest\u0026gt;  request these layer_urls above to handle any redirection response to get real downloading urls\n supernodes use these real downloading urls to preheat layers of this image\n Response: Content-type: application/json HTTP CodeResponse Body  200 Success response: { \u0026ldquo;code\u0026rdquo;: 200, \u0026ldquo;data\u0026rdquo;: { \u0026ldquo;taskId\u0026rdquo;: \u0026ldquo;\u0026lt;string\u0026gt;\u0026ldquo; } } Use \u0026lsquo;taskId\u0026rsquo; to query the status of the preheat task. 200 Error Response: { \u0026ldquo;code\u0026rdquo;: 400, \u0026ldquo;msg\u0026rdquo;: \u0026ldquo;\u0026lt;detailed error message\u0026gt;\u0026ldquo; }  \n  GET /api/preheat/{taskId}  query the current status of the preheat task which id is taskId\n  Response: Content-type: application/json HTTP CodeResponse Body  200 Success response: { \u0026ldquo;code\u0026rdquo;: 200, \u0026ldquo;data\u0026rdquo;: { \u0026ldquo;taskId\u0026rdquo;: \u0026ldquo;\u0026lt;string\u0026gt;\u0026rdquo;, \u0026ldquo;status\u0026rdquo;: \u0026ldquo;RUNNING|SUCCESS|FAIL\u0026rdquo; } }  200 Error Response: { \u0026ldquo;code\u0026rdquo;: 400, \u0026ldquo;msg\u0026rdquo;: \u0026ldquo;\u0026lt;detailed error message\u0026gt;\u0026ldquo; }   "
},
{
	"uri": "https://d7y.io/overview/terminology/",
	"title": "Terminology",
	"tags": [],
	"description": "",
	"content": "This topic lists the common terms used throughout Dragonfly. Supernode Supernode is a long-time process with two primary responsibilities:\n It\u0026rsquo;s the tracker and scheduler in the P2P network that choose appropriate downloading net-path for each peer. It\u0026rsquo;s also a CDN server that caches downloaded data from source to avoid downloading same files repeatedly.  dfget Dfget is the client of Dragonfly used for downloading files. It\u0026rsquo;s similar to wget.\nAt the same time, it also plays the role of peer, which can transfer data between each other in P2P network.\ndfdaemon Dfdaemon is used for pulling images only. It establishes a proxy between dockerd/pouchd and registry.\nDfdaemon filters out layer fetching requests from all requests sent by dockerd/pouchd when pulling images, then uses dfget to downloading these layers.\n"
},
{
	"uri": "https://d7y.io/cli_reference/dfget/",
	"title": "dfget",
	"tags": [],
	"description": "",
	"content": " dfget This topic explains how to use the dfget command.\nNAME dfget - the client of Dragonfly, a non-interactive P2P downloader\nSYNOPSIS dfget -u [URL] [options]\u0026hellip;\nOPTIONS  -h, --help show this help message and exit --url URL, -u URL will download a file from this url --output OUTPUT, -O OUTPUT, -o OUTPUT output path that not only contains the dir part but also name part --md5 MD5, -m MD5 expected file md5 --callsystem CALLSYSTEM system name that executes dfget,its format is company_department_appName --notbs not back source when p2p fail --locallimit LOCALLIMIT, -s LOCALLIMIT rate limit about a single download task,its format is 20M/m/K/k --totallimit TOTALLIMIT rate limit about the whole host,its format is 20M/m/K/k --identifier IDENTIFIER, -i IDENTIFIER identify download task,it is available merely when md5 param not exist --timeout TIMEOUT, --exceed TIMEOUT, -e TIMEOUT download timeout(second) --filter FILTER, -f FILTER filter some query params of url ,e.g. -f 'key\u0026amp;sign' will filter key and sign query param.in this way,different urls correspond one same download task that can use p2p mode --showbar, -b show progress bar --pattern {p2p,cdn}, -p {p2p,cdn} download pattern,cdn pattern not support totallimit --version, -v version --node NODE, -n NODE specify nodes --console show log on console --header HEADER http header, e.g. --header=\u0026quot;Accept: *\u0026quot; --header=\u0026quot;Host: abc\u0026quot; --dfdaemon caller is from df-daemon  FILES /etc/dragonfly.conf default configuration file for dfget, it configures the address of the supernode.\n[node] address=127.0.0.1,127.0.0.2  ${HOME}/.small-dragonfly This directory is created by dfget when you first time start it.\n.small-dragonfly/ ├── data/ # stores temporary data downloaded by dfget ├── dfdaemon/ │ └── data/ # default, stores temporary data generated by dfdaemon ├── logs/ │ ├── dfclient.log # dfget's log file │ ├── dfserver.log # log file of peer server launched by dfget │ └── dfdaemon.log # dfdaemon's log file └── meta/ └── host.meta # stores meta information: peer server port  "
},
{
	"uri": "https://d7y.io/user_guide/download_files/",
	"title": "Downloading Files",
	"tags": [],
	"description": "",
	"content": "Things are done differently when you download container images and download general files with Dragonfly. Prerequisites  You are using Linux operating system. You have installed Python 2.7+, and added the Python directory to the PATH environment variable. The supernode service is started.\nFor more information on the installation of supernodes, see Installing Server.\n   Downloading container images  Specify the supernodes.\na. Open the Dragonfly configuration file.\nvi /etc/dragonfly.conf  b. Add the IP of supernodes separated by comma to the configuration file.\n[node] address=nodeIp1,nodeIp2  Start the dfget proxy (dfdaemon).\n# Start dfdaemon and specify the image repo URL. The default port is `65001`. dfdaemon --registry https://xxx.xx.x # Review dfdaemon logs tailf ~/.small-dragonfly/logs/dfdaemon.log  To list all available parameters for dfdaemon, run dfdeaemon -h.\n  Configure the Daemon Mirror.\na. Modify the configuration file /etc/docker/daemon.json.\nvi /etc/docker/daemon.json  For more information on /etc/docker/daemon.json, see Docker documentation.\n b. Add or update the configuration item registry-mirrors in the configuration file.\n\u0026quot;registry-mirrors\u0026quot;: [\u0026quot;http://127.0.0.1:65001\u0026quot;]  c. Restart Docker daemon.\nsystemctl restart docker  Download an image with Dragonfly.\ndocker pull {imageName}  Don\u0026rsquo;t include the image repo URL in {imageName}, because the repo URL has been specified with the registry parameter when starting dfdaemon.\n   Downloading General Files  Specify the supernodes in one of the following ways.\n Specifying with the configuration file.\n# Open the Dragonfly configuration file. vi /etc/dragonfly.conf # Add the IP of supernodes separated by comma to the configuration file [node] address=nodeIp1,nodeIp2  Specifying with the parameter in the command line.\ndfget -u \u0026quot;http://www.taobao.com\u0026quot; -o /tmp/test.html --node nodeIp1,nodeIp2  When using this method, you must add the node parameter every time when you run the dfget command. And the parameter in the command line takes precedence over the configuration file.\n   Download general files with Dragonfly in one of the following ways.\n Download files with the default /etc/dragonfly.conf configuration.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot;  To list all available parameters for dfget, run dfget -h.\n  Download files with your specified supernodes.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot; --node \u0026quot;127.0.0.1\u0026quot;  Download files to your specified output file.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot; -o a.txt    After this Task To review the downloading log, run less ~/.small-dragonfly/logs/dfclient.log.\n"
},
{
	"uri": "https://d7y.io/overview/",
	"title": "Overview",
	"tags": [],
	"description": "",
	"content": "Get to know Dragonfly and the common terminologies.\n What Is Dragonfly?  Dragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution.  Terminology  This topic lists the common terms used throughout Dragonfly.  "
},
{
	"uri": "https://d7y.io/user_guide/supernode_configuration/",
	"title": "Supernode Configuration",
	"tags": [],
	"description": "",
	"content": "The supernode is written in Java based on Spring Boot. You can easily set properties with command line parameters or with the configuration file. Supernode Properties Simple Property    Property Name Default Value Description     supernode.baseHome /home/admin/supernode Working directory of the supernode   supernode.systemNeedRate 20 Network rate reserved for the system (Unit: MB/s)   supernode.totalLimit 200 Network rate reserved for the supernode (Unit: MB/s)   supernode.schedulerCorePoolSize 10 Core pool size of ScheduledExecutorService   supernode.dfgetPath /usr/local/bin/dfget/ The dfget path    Cluster Property supernode.cluster This is an array property, and every member of it has these attributes:\n   Name Default Value Description     ip None The ip of the cluster member.   registerPort 8001 The register port of the cluster member.   downloadPort 8002 The download port of the cluster member.     Config it in .properties file, for example:\nsupernode.cluster[0].ip = '192.168.0.1' supernode.cluster[0].registerPort = 8001 supernode.cluster[1].ip = '192.168.0.2'  Config it in .yaml file, for example:\nsupernode: cluster: - ip: '192.168.0.1' registerPort: 8001 - ip: '192.168.0.2'   Setting Properties You have two options when setting properties of a supernode.\n Setting properties with command line parameters.\njava -D\u0026lt;propertyName\u0026gt;=\u0026lt;propertyValue\u0026gt; -jar supernode.jar  Setting properties with the configuration file.\njava -Dspring.config.location=./config.properties,\u0026lt;otherConfigFilePath\u0026gt; -jar supernode.jar  "
},
{
	"uri": "https://d7y.io/quick_start/",
	"title": "Quick Start",
	"tags": [],
	"description": "",
	"content": "Simply by starting a supernode in your Docker container, and installing the Dragonfly client, you can start downloading with Dragonfly. Prerequisites You have started your Docker container.\nStarting a Supernode in Your Docker Container  Pull the docker image we provided.\n# Replace ${imageName} with the real image name docker pull ${imageName}  Start a supernode.\n# Replace ${imageName} with the real image name docker run -d -p 8001:8001 -p 8002:8002 ${imageName}   We provided two images in different locations:\n China: registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0 US: registry.us-west-1.aliyuncs.com/alidragonfly/supernode:0.2.0  For example, if you\u0026rsquo;re in China, run the following commands:\ndocker pull registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0 docker run -d -p 8001:8001 -p 8002:8002 registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0  Installing Dragonfly Client  Download a package of the client.\ncd $HOME # Replace ${package} with a package appropriate for your operating system and location wget ${package}  Unzip the package.\ntar -zxf df-client_0.2.0_linux_amd64.tar.gz  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=$PATH:$HOME/df-client/   We provided different packages to suit your need. Please choose one and replace the ${package} with it.\n If you\u0026rsquo;re in China:\n Linux 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_darwin_amd64.tar.gz\n  If you\u0026rsquo;re not in China:\n Linux 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_darwin_amd64.tar.gz\n   For example, if you\u0026rsquo;re in China and using Linux, run the following commands:\ncd $HOME wget http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz tar -zxf df-client_0.2.0_linux_amd64.tar.gz # execute or add this line to ~/.bashrc export PATH=$PATH:$HOME/df-client/  Downloading a File with Dragonfly Once you have installed the Dragonfly client, you can use the dfget command to download a file.\ndfget -u 'https://github.com/alibaba/Dragonfly/blob/master/docs/images/logo.png' -o /tmp/logo.png  For more information on the dfget command, see dfget.\n Pulling an Image with Dragonfly  Start dfdaemon with a specified registry, such as https://index.docker.io.\nnohup dfdaemon --registry https://index.docker.io \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;  Add the following line to the dockerd configuration file /etc/docker/daemon.json.\n\u0026quot;registry-mirrors\u0026quot;: [\u0026quot;http://127.0.0.1:65001\u0026quot;]  Restart dockerd.\nsystemctl restart docker  Download an image with Dragonfly.\ndocker pull nginx:latest   Related Topics  Installing Server Installing Client Downloading Files supernode Configuration dfget "
},
{
	"uri": "https://d7y.io/user_guide/",
	"title": "User Guide",
	"tags": [],
	"description": "",
	"content": "Understand how to use Dragonfly from installing the server and client to downloading files.\n Installing Server  This topic explains how to install the Dragonfly server.  Installing Client  You have two options when installing the Dragonfly client: installing from the latest package, or installing from the source code.  Downloading Files  Things are done differently when you download container images and download general files with Dragonfly.  Supernode Configuration  The supernode is written in Java based on Spring Boot. You can easily set properties with command line parameters or with the configuration file.  "
},
{
	"uri": "https://d7y.io/cli_reference/",
	"title": "CLI Reference",
	"tags": [],
	"description": "",
	"content": "Understand the details of CLI commands.\n dfdaemon  dfdaemon This topic explains how to use the dfdaemon command. NAME dfdaemon - a proxy between pouchd/dockerd and registry used for pulling images. SYNOPSIS dfdaemon [options]\u0026hellip; OPTIONS -callsystem string caller name (default \u0026quot;com_ops_dragonfly\u0026quot;) -certpem string cert.pem file path -dfpath string dfget path (default is your installed path) -h\thelp -hostIp string dfdaemon host ip, default: 127.0.0.1 (default \u0026quot;127.0.0.1\u0026quot;) -keypem string key.pem file path -localrepo string temp output dir of dfdaemon (default is \u0026quot;${HOME}/.\n dfget  dfget This topic explains how to use the dfget command. NAME dfget - the client of Dragonfly, a non-interactive P2P downloader SYNOPSIS dfget -u [URL] [options]\u0026hellip; OPTIONS -h, --help show this help message and exit --url URL, -u URL will download a file from this url --output OUTPUT, -O OUTPUT, -o OUTPUT output path that not only contains the dir part but also name part --md5 MD5, -m MD5 expected file md5 --callsystem CALLSYSTEM system name that executes dfget,its format is company_department_appName --notbs not back source when p2p fail --locallimit LOCALLIMIT, -s LOCALLIMIT rate limit about a single download task,its format is 20M/m/K/k --totallimit TOTALLIMIT rate limit about the whole host,its format is 20M/m/K/k --identifier IDENTIFIER, -i IDENTIFIER identify download task,it is available merely when md5 param not exist --timeout TIMEOUT, --exceed TIMEOUT, -e TIMEOUT download timeout(second) --filter FILTER, -f FILTER filter some query params of url ,e.\n "
},
{
	"uri": "https://d7y.io/api_reference/",
	"title": "API Reference",
	"tags": [],
	"description": "",
	"content": "Know the details of our APIs.\n APIs Provided by Supernode  This topic explains how to use the APIs provided by Supernode.  Preheat API  This topic explains how to use the Preheat API.  "
},
{
	"uri": "https://d7y.io/faq/",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": " FAQ How can I pull images by Dragonfly See Use Dragonfly to Pull an Image\nHow can I download files by Dragonfly See Use Dragonfly to Download a File\nWhat is SuperNode SuperNode is a long-time process with two primary responsibilities:\n It\u0026rsquo;s the tracker and scheduler in the P2P network that choose appropriate downloading net-path for each peer. It\u0026rsquo;s also a CDN server that caches downloaded data from source to avoid downloading same files repeatedly.  What is dfget Dfget is the client of Dragonfly used for downloading files. It\u0026rsquo;s similar to using wget.\nAt the same time, it also plays the role of peer, which can transfer data between each other in p2p network.\nWhat is dfdaemon Dfdaemon is only used for pulling images. It establishes a proxy between dockerd/pouchd and registry.\nDfdaemon filters out layer fetching requests from all requests send by dockerd/pouchd when pulling images, then it uses dfget to downloading these layers.\n"
},
{
	"uri": "https://d7y.io/apis/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Drgonfly SuperNode API \nOverview API is an HTTP API served by Dragonfly\u0026rsquo;s SuperNode. It is the API dfget or Harbor uses to communicate with the supernode.\nVersion information Version : 0.1\nURI scheme BasePath : /v1.24\nSchemes : HTTP, HTTPS\nTags  Peer : Create and manage peer nodes in peer networks. Piece : create and manage image/file pieces in supernode. PreheatTask : Create and manage image or file preheat task in supernode. Task : create and manage image/file distribution task in supernode.  Consumes  application/json text/plain  Produces  application/json text/plain  \nPaths \nPing GET /_ping  Description This is a dummy endpoint you can use to test if the server is accessible.\nResponses    HTTP Code Description Schema     200 no error string   500 An unexpected server error occurred. Error    Example HTTP response Response 200 json : \u0026quot;OK\u0026quot;  \nregister dfget in Supernode as a peer node POST /peers  Description dfget sends request to register in Supernode as a peer node\nParameters    Type Name Description Schema     Body body optional request body which contains peer registrar information. PeerCreateRequest    Responses    HTTP Code Description Schema     201 no error PeerCreateResponse   400 bad parameter Error   500 An unexpected server error occurred. Error    \nget a peer in supernode GET /peers/{id}  Description return low-level information of a peer in supernode.\nParameters    Type Name Description Schema     Path id required ID of peer string    Responses    HTTP Code Description Schema     200 no error PeerInfo   404 An unexpected 404 error occurred. Error   500 An unexpected server error occurred. Error    Produces  application/json  \ndelete a peer in supernode DELETE /peers/{id}  Description dfget stops playing a role as a peer in peer network constructed by supernode. when dfget lasts in five minutes without downloading or uploading task, dfget automatically sends a DELETE /peers/{id} request.\nParameters    Type Name Description Schema     Path id required ID of peer string    Responses    HTTP Code Description Schema     204 no error No Content   404 no such peer 4ErrorResponse   500 An unexpected server error occurred. Error    \nGet a piece GET /pieces/{id}  Description Get detailed information of a piece in supernode.\nParameters    Type Name Description Schema     Path id required ID of piece string    Responses    HTTP Code Description Schema     200 no error \u0026lt; PieceInfo \u0026gt; array   404 no such task 4ErrorResponse   500 An unexpected server error occurred. Error    Produces  application/json  \nUpdate a piece PUT /pieces/{id}  Description Update some information of piece, like status of piece.\nParameters    Type Name Description Schema     Path id required ID of piece string   Body PieceUpdateRequest optional request body which contains task update information PieceUpdateRequest    Responses    HTTP Code Description Schema     200 no error No Content   404 An unexpected 404 error occurred. Error   500 An unexpected server error occurred. Error    Consumes  application/json  Produces  application/json  \nCreate a Preheat Task POST /preheats  Description Create a preheat task in supernode to first download image/file which is ready. Preheat action will shorten the period for dfget to get what it wants. In details, after preheat action finishes downloading image/file to supernode, dfget can send request to setup a peer-to-peer network immediately.\nParameters    Type Name Description Schema     Body PreheatCreateRequest optional request body which contains preheat task creation information PreheatCreateRequest    Responses    HTTP Code Description Schema     200 no error PreheatCreateResponse   400 bad parameter Error   500 An unexpected server error occurred. Error    \nList Preheat Tasks GET /preheats  Description List preheat tasks in supernode of Dragonfly. This API can list all the existing preheat tasks in supernode. Note, when a preheat is finished after PreheatGCThreshold, it will be GCed, then this preheat will not be gotten by preheat tasks list API.\nResponses    HTTP Code Description Schema     200 no error \u0026lt; PreheatInfo \u0026gt; array   400 bad parameter Error   500 An unexpected server error occurred. Error    \nGet a preheat task GET /preheats/{id}  Description get detailed information of a preheat task in supernode.\nParameters    Type Name Description Schema     Path id required ID of preheat task string    Responses    HTTP Code Description Schema     200 no error PreheatInfo   404 no such preheat task 4ErrorResponse   500 An unexpected server error occurred. Error    Produces  application/json  \ncreate a task POST /tasks  Description Create a peer-to-peer downloading task in supernode.\nParameters    Type Name Description Schema     Body body optional request body which contains task creation information TaskCreateRequest    Responses    HTTP Code Description Schema     201 no error TaskCreateResponse   400 bad parameter Error   500 An unexpected server error occurred. Error    \nget a task GET /tasks/{id}  Description return low-level information of a task in supernode.\nParameters    Type Name Description Schema     Path id required ID of task string    Responses    HTTP Code Description Schema     200 no error TaskInfo   404 An unexpected 404 error occurred. Error   500 An unexpected server error occurred. Error    Produces  application/json  \nupdate a task PUT /tasks/{id}  Description update information of a task.\nParameters    Type Name Description Schema     Path id required ID of task string   Body TaskUpdateRequest optional request body which contains task update information\u0026rdquo; TaskUpdateRequest    Responses    HTTP Code Description Schema     200 no error No Content   404 An unexpected 404 error occurred. Error   500 An unexpected server error occurred. Error    Consumes  application/json  Produces  application/json  \ndelete a task DELETE /tasks/{id}  Description delete a peer-to-peer task in supernode.\nParameters    Type Name Description Schema     Path id required ID of task string    Responses    HTTP Code Description Schema     204 no error No Content   404 no such peer 4ErrorResponse   500 An unexpected server error occurred. Error    \nGet pieces in task GET /tasks/{id}/pieces  Description Get fixed number of pieces in a task. The number is set in query.\nParameters    Type Name Description Schema     Path id required ID of task string   Query num optional Request number of pieces of task. If request number is larger than the total pieces in supernode,\nsupernode returns the total pieces of task. If not set, supernode will set 4 by default. integer (int64)    Responses    HTTP Code Description Schema     200 no error \u0026lt; PieceInfo \u0026gt; array   404 no such task 4ErrorResponse   500 An unexpected server error occurred. Error    Produces  application/json  \nDefinitions \nError    Name Schema     message optional string    \nErrorResponse It contains a code that identify which error occurred for client processing and a detailed error message to read.\n   Name Description Schema     code optional the code of this error, it\u0026rsquo;s convenient for client to process with certain error. integer   message optional detailed error message string    \nPeerCreateRequest PeerCreateRequest is used to create a peer instance in supernode. Usually, when dfget is going to register in supernode as a peer, it will send PeerCreateRequest to supernode.\n   Name Description Schema     ID optional Peer ID of dfget client. Every peer has a unique ID among peer network. string   IP optional IP address which peer client carries string (ipv4)   callSystem optional This field is for debugging. When caller of dfget is using it to files, he can pass callSystem\nname to dfget. When this field is passing to supernode, supernode has ability to filter them via some black/white list to guarantee security, or some other purposes. Minimum length : 1 string   dfdaemon optional tells whether it is a call from dfdaemon. boolean   hostName optional host name of peer client node, as a valid RFC 1123 hostname. Minimum length : 1 string (hostname)   path optional This is actually an HTTP URLPATH of dfget. Other peers can access the source file via this PATH. string   port optional when registering, dfget will setup one uploader process. This one acts as a server for peer pulling tasks.\nThis port is which this server listens on. Minimum value : 30000 Maximum value : 65535 integer (int64)   version optional version number of dfget binary string    \nPeerCreateResponse ID of created peer.\n   Name Description Schema     ID optional ID of created peer. string    \nPeerInfo The detailed information of a peer in supernode.\n   Name Description Schema     ID optional ID of peer string   IP optional IP address which peer client carries string (ipv4)   callSystem optional This field is for debugging. When caller of dfget is using it to files, he can pass callSystem\nname to dfget. When this field is passing to supernode, supernode has ability to filter them via some black/white list to guarantee security, or some other purposes. Minimum length : 1 string   dfdaemon optional tells whether it is a call from dfdaemon. boolean   hostName optional host name of peer client node, as a valid RFC 1123 hostname. Minimum length : 1 string (hostname)   path optional This is actually an HTTP URLPATH of dfget. Other peers can access the source file via this PATH. string   port optional when registering, dfget will setup one uploader process. This one acts as a server for peer pulling tasks.\nThis port is which this server listens on. Minimum value : 30000 Maximum value : 65535 integer (int64)   version optional version number of dfget binary string    \nPieceInfo Peer\u0026rsquo;s detailed information in supernode.\n   Name Description Schema     ID optional ID of the peer string    \nPieceUpdateRequest    Name Schema     ID optional string    \nPreheatCreateRequest Request option of creating a preheat task in supernode.\n   Name Description Schema     filter optional URL may contains some changeful query parameters such as authentication parameters. Dragonfly will filter these parameter via \u0026lsquo;filter\u0026rsquo;. The usage of it is that different URL may generate the same download taskID. string   headers optional If there is any authentication step of the remote server, the headers should contains authenticated information.\nDragonfly will sent request taking the headers to remote server. \u0026lt; string, string \u0026gt; map   identifier optional This field is used for generating new downloading taskID to indetify different downloading task of remote URL. string   type optional this must be image or file string   url optional the image or file location string    \nPreheatCreateResponse Response of a preheat creation request.\n   Name Schema     ID optional string    \nPreheatInfo return detailed information of a preheat task in supernode. An image preheat task may contain multiple downloading task because that an image may have more than one layer.\n   Name Description Schema     ID optional ID of preheat task. string   finishTime optional the preheat task finish time string (date-time)   startTime optional the preheat task start time string (date-time)   status optional The status of preheat task.\nWAITING \u0026mdash;\u0026ndash;\u0026gt; RUNNING \u0026mdash;\u0026ndash;\u0026gt; SUCCESS\n|\u0026ndash;\u0026gt; FAILED\nThe initial status of a created preheat task is WAITING.\nIt\u0026rsquo;s finished when a preheat task\u0026rsquo;s status is FAILED or SUCCESS.\nA finished preheat task\u0026rsquo;s information can be queried within 24 hours. enum (WAITING, RUNNING, FAILED, SUCCESS)    \nTaskCreateRequest    Name Description Schema     headers optional extra HTTP headers sent to the rawURL.\nThis field is carried with the request to supernode. Supernode will extract these HTTP headers, and set them in HTTP downloading requests\nfrom source server as user\u0026rsquo;s wish. \u0026lt; string, string \u0026gt; map   identifier optional special attribute of remote source file. This field is used with taskURL to generate new taskID to\nindetify different downloading task of remote source file. For example, if user A and user B uses\nthe same taskURL and taskID to download file, A and B will share the same peer network to distribute files.\nIf user A additionally adds an indentifier with taskURL, while user B still carries only taskURL, then A\u0026rsquo;s\ngenerated taskID is different from B, and the result is that two users use different peer networks. string   md5 optional md5 checksum for the resource to distribute. dfget catches this parameter from dfget\u0026rsquo;s CLI\nand passes it to supernode. When supernode finishes downloading file/image from the source location,\nit will validate the source file with this md5 value to check whether this is a valid file. string   rawURL optional The is the resource\u0026rsquo;s URL which user uses dfget to download. The location of URL can be anywhere, LAN or WAN.\nFor image distribution, this is image layer\u0026rsquo;s URL in image registry.\nThe resource url is provided by command line parameter. string   taskURL optional taskURL is generated from rawURL. rawURL may contains some queries or parameter, dfget will filter some queries via\n\u0026ndash;filter parameter of dfget. The usage of it is that different rawURL may generate the same taskID. string    \nTaskCreateResponse response get from task creation request.\n   Name Description Schema     ID optional ID of the created task. string    \nTaskInfo detailed information about task in supernode.\n   Name Description Schema     ID optional ID of the task. string    \nTaskUpdateRequest request used to update task attributes.\n   Name Description Schema     ID optional ID of the created task. string    "
},
{
	"uri": "https://d7y.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://d7y.io/",
	"title": "Dragonfly",
	"tags": [],
	"description": "",
	"content": "       \nDragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution. At Alibaba, every month Dragonfly is invoked two billion times and distributes 3.4PB of data. Dragonfly has become one of the most important pieces of infrastructure at Alibaba.\nWhile container technologies makes DevOps life easier most of the time, it surely brings some challenges: for example the efficiency of image distribution, especially when you have to replicate image distribution on several hosts.\nDragonfly works extremely well with both Docker and PouchContainer in this scenario. It\u0026rsquo;s also compatible with containers of other formats. It delivers up to 57 times the throughput of native docker and saves up to 99.5% of the out bandwidth of registry.\nDragonfly makes it simple and cost-effective to set up, operate, and scale any kind of file, image, or data distribution.\nWhy Dragonfly? This project is an open-source version of the Dragonfly used at Alibaba. It has the following features:\nMore Alibaba-internal features will be made available to open-source users soon. Stay tuned!\n  P2P-based file distribution: By using the P2P technology for file transmission, it makes the most out of the bandwidth resources of each peer to improve downloading efficiency, and saves a lot of cross-IDC bandwidth, especially the costly cross-board bandwidth. Non-invasive support to all kinds of container technologies: Dragonfly can seamlessly support various containers for distributing images. Host level speed limit: In addition to rate limit for the current download task like many other downloading tools (for example wget and curl), Dragonfly also provides rate limit for the entire host. Passive CDN: The CDN mechanism can avoid repetitive remote downloads. Strong consistency: Dragonfly can make sure that all downloaded files are consistent even if users do not provide any check code (MD5). Disk protection and highly efficient IO: Prechecking disk space, delaying synchronization, writing file blocks in the best order, isolating net-read/disk-write, and so on. High performance: Cluster Manager is completely closed-loop, which means that it doesn\u0026rsquo;t rely on any database or distributed cache, processing requests with extremely high performance. Auto-isolation of Exception: Dragonfly will automatically isolate exception nodes (peer or Cluster Manager) to improve download stability. No pressure on file source: Generally, only a few Cluster Managers will download files from the source. Support standard HTTP header: Support submitting authentication information through HTTP header. Effective concurrency control of Registry Auth: Reduce the pressure on the Registry Auth Service. Simple and easy to use: Very few configurations are needed.  How Does It Stack Up Against Traditional Solution? We carried out an experiment to compare the performance of Dragonfly and wget.\n   Test Environment      Dragonfly Server 2 * (24-Core 64GB-RAM 2000Mb/s)   File Source Server 2 * (24-Core 64GB-RAM 2000Mb/s)   Client 4-Core 8GB-RAM 200Mb/s   Target File Size 200MB   Experiment Date April 20, 2016    The expeirment result is as shown in the following figure.\nAs you can see in the chart, for Dragonfly, no matter how many clients are downloading, the average downloading time is always about 12 seconds. But for wget, the downloading time keeps increasing with the number of clients. When the number of wget clients reaches 1,200, the file source crashed and therefore cannot serve any client.\nHow Does It Work? Dragonfly works slightly differently when downloading general files and downloading container images.\nDownloading General Files The Cluster Manager is also called a supernode, which is responsible for CDN and scheduling every peer to transfer blocks between each other. dfget is the P2P client, which is also called \u0026ldquo;peer\u0026rdquo;. It\u0026rsquo;s mainly used to download and share blocks.\nDownloading Container Images Registry is similar to the file server above. dfget proxy is also called dfdaemon, which intercepts HTTP requests from docker pull or docker push, and then decides which requests to process with dfget.\nDownloading Blocks Every file is divided into multiple blocks, which are transmitted between peers. Each peer is a P2P client. Cluster Manager will check if the corresponding file exists in the local disk. If not, it will be downloaded into Cluster Manager from file server.\nWho has adopted Dragonfly? Below are the adoptors of project Dragonfly. If you are using to Dragonfly to improve your distribution, please contact us with.\n\u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp;\nLicense Dragonfly is available under the Apache 2.0 License.\n"
},
{
	"uri": "https://d7y.io/roadmap/",
	"title": "Roadmap",
	"tags": [],
	"description": "",
	"content": " CNCF Ecosystem  Deploy SuperNode using Helm in Kubernetes Deploy dfget \u0026amp; dfdaemon using DaemonSet in Kubernetes Integration with Harbor: preheat image feature  Security  Support private container image Support authentication in SuperNode API Different encryption algorithm in data transmission  Efficiency  Dynamic downloading rate limiting and scheduling algorithm Use IPFS to share block datas between SuperNodes  Openness  Plug-In policy for CNCF projects Highly user-customized modules Refactor SuperNode with Golang  Scalability  Simplify the complexity of scaling SuperNodes in Kubernetes  Stability  Cluster the SuperNode to decrease possibility of failure  "
},
{
	"uri": "https://d7y.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]